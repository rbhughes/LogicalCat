<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Logicalcat by rbhughes</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
	<img src="https://s3.amazonaws.com/logicalcat-images/logo.png" alt="LogicalCat" >
	<p>
          <h2 class='center'>Simple Geoscience Search</h2>
	</p>


	<hr>
	<ul>
	  <li><a href="https://github.com/rbhughes/lc_dox_crawlers/blob/master/README.md">Business Documents</a></li>
	  <li><a href="https://github.com/rbhughes/lc_epf_crawlers/wiki">E&P Files</a></li>
	  <li><a href="https://github.com/rbhughes/lc_pet_crawlers/blob/master/README.md">IHS PETRA</a></li>
	  <li><a href="https://github.com/rbhughes/lc_tks_crawlers/wiki">IHS Kingdom Suite</a></li>
	  <li><a href="https://github.com/rbhughes/lc_ggx_crawlers/blob/master/README.md">LMKR GeoGraphix Discovery</a></li>
	  <li><a href="https://github.com/rbhughes/lc_pdm_crawlers/wiki">PPDM</a></li>
	</ul>
	<hr>
	<br>

	<div class="download"><a href="https://github.com/rbhughes/LogicalCat/zipball/master"><img src="https://s3.amazonaws.com/logicalcat-images/down_arrow.png" alt="LogicalCat" height="32px" >&nbsp Free Demo (biz docs)</a></div>

      </header>
      <section>

        <h3>Welcome to LogicalCat!</h3>
	<p>LogicalCat LLC was founded in 2008 to solve the problem of messy geoscience data at Energy Exploration and Production Companies. We believe that traditional data management schemes at E&P companies relying on tedious naming conventions or single-vendor solutions are outdated and that Search is an elegant solution to dealing with chaos.</p>


        <h3>What's this all about?</h3>
	<p>LogicalCat is a browser-based, vendor-neutral search engine for projects and data commonly used by geologists and engineers in upstream exploration. You can crawl your intranet and index data within files and project databases. For example, search for a UWI and you might get "hits" from a bunch of LAS files and a few Discovery project databases. It's like Google for stuff geotechs struggle with every day.</p>
<img src="https://s3.amazonaws.com/logicalcat-images/screencap.png" alt="LogicalCat" >
        <br>
        <br>


        <h3>Some things you might use it for:</h3>
	<dl>
	  <dt>Locate Assets</dt>
	  <dd>Where are those LAS files? What are the top 10 most active GeoGraphix projects? How many duplicate SEGY files do we have? Now you can know. Instantly.</dd>

	  <dt>Start and Maintain Data Management </dt>
	  <dd>There is no shortage of structured data management practices and procedures for the E&P Industry. LogicalCat can help you take that first <em>vendor neutral</em> step toward getting and staying organized.</dd>

	  <dt>Mergers and Acquisitions</dt>
	  <dd>LogicalCat can serve as your rapid reconnaissance tool. Selling? Use it to prepare a data room for your asset sale or help you discern proprietary from vendor data. Buying? Quickly discover interpretation boundaries or which projects need upgrading.</dd>

	  <dt>IT Operations</dt>
	  <dd>Non-geoscientists can objectively gauge which projects are the most active and plan backups and disaster recovery accordingly. Old projects can be safely archived while still retaining full metadata of their contents. Disk usage can be allocated fairly among business units.</dd>

	</dl>

        <h3>Try out the Free Demo</h3>

	<p>The demo includes only the "Business Documents" crawler. There's nothing particularly E&P-centric about it, but it should give you a pretty good idea of how LogicalCat works. This crawler is basically a web-app GUI for the fantastic Apache <a href="http://tika.apache.org">Tika</a> project's content analysis toolkit. Enjoy!</p> 


        <h3>Contact</h3>
	<div id="contact">
	  <a href="mailto:info@logicalcat.com">info@logicalcat.com</a><span class="right">303-949-8125</span>
        </div>


        <h3>Software Requirements</h3>
	<ul>
	  <li>Windows 7 or 8, 64-bit (32-bit is an option too)</li>
	  <li>A reasonably modern browser: Firefox, Chrome, Internet Explorer 10+</li>
	  <li>The installer needs admin rights and will write to: <code>c:\logicalcat</code></li>
	  <li>You will likely want to use a custom account or your own login for the Windows Service running the crawl (the installer will prompt you)</li>
	  <li>Ports used: 8008, 9200, 9300</li>
	  <li>License server? No! We hate license servers</li>
	</ul>

<!--
<pre><code>$ cd your_repo_root/repo_name
$ git fetch origin
$ git checkout gh-pages
</code></pre>
-->



	


      </section>

      <footer>
        <p><small>Hosted on GitHub Pages | Trademarks property of their respective owners | Copyright Â© 2013 LogicalCat LLC</small></p>
      </footer>

    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
